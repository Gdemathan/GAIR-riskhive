{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get('OPENAI_API_KEY'),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "from kaggle_submission import SubmissionBase\n",
    "\n",
    "questions = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V1 - Simple Context Improvement**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Prediction 1, question 1 : a\n",
      " --> Prediction 1, question 2 : a\n",
      " --> Prediction 1, question 3 : c\n",
      " --> Prediction 1, question 4 : a\n",
      " --> Prediction 1, question 5 : a\n",
      " --> Prediction 1, question 6 : b\n",
      " --> Prediction 1, question 7 : d\n",
      " --> Prediction 1, question 8 : a\n",
      " --> Prediction 1, question 9 : b\n",
      " --> Prediction 1, question 10 : a\n",
      " --> Prediction 1, question 11 : c\n",
      " --> Prediction 1, question 12 : a\n",
      " --> Prediction 1, question 13 : b\n",
      " --> Prediction 1, question 14 : d\n",
      " --> Prediction 1, question 15 : a\n",
      " --> Prediction 1, question 16 : c\n",
      " --> Prediction 1, question 17 : b\n",
      " --> Prediction 1, question 18 : a\n",
      " --> Prediction 1, question 19 : a\n",
      " --> Prediction 1, question 20 : c\n",
      " --> Prediction 1, question 21 : d\n",
      " --> Prediction 1, question 22 : a\n",
      " --> Prediction 1, question 23 : a\n",
      " --> Prediction 1, question 24 : d\n",
      " --> Prediction 2, question 1 : a\n",
      " --> Prediction 2, question 2 : a\n",
      " --> Prediction 2, question 3 : c\n",
      " --> Prediction 2, question 4 : b\n",
      " --> Prediction 2, question 5 : a\n",
      " --> Prediction 2, question 6 : b\n",
      " --> Prediction 2, question 7 : d\n",
      " --> Prediction 2, question 8 : a\n",
      " --> Prediction 2, question 9 : b\n",
      " --> Prediction 2, question 10 : a\n",
      " --> Prediction 2, question 11 : b\n",
      " --> Prediction 2, question 12 : c\n",
      " --> Prediction 2, question 13 : a\n",
      " --> Prediction 2, question 14 : d\n",
      " --> Prediction 2, question 15 : a\n",
      " --> Prediction 2, question 16 : c\n",
      " --> Prediction 2, question 17 : b\n",
      " --> Prediction 2, question 18 : a\n",
      " --> Prediction 2, question 19 : a\n",
      " --> Prediction 2, question 20 : c\n",
      " --> Prediction 2, question 21 : c\n",
      " --> Prediction 2, question 22 : a\n",
      " --> Prediction 2, question 23 : a\n",
      " --> Prediction 2, question 24 : d\n",
      " --> Prediction 3, question 1 : a\n",
      " --> Prediction 3, question 2 : a\n",
      " --> Prediction 3, question 3 : c\n",
      " --> Prediction 3, question 4 : d\n",
      " --> Prediction 3, question 5 : a\n",
      " --> Prediction 3, question 6 : b\n",
      " --> Prediction 3, question 7 : d\n",
      " --> Prediction 3, question 8 : d\n",
      " --> Prediction 3, question 9 : b\n",
      " --> Prediction 3, question 10 : b\n",
      " --> Prediction 3, question 11 : a\n",
      " --> Prediction 3, question 12 : c\n",
      " --> Prediction 3, question 13 : a\n",
      " --> Prediction 3, question 14 : d\n",
      " --> Prediction 3, question 15 : a\n",
      " --> Prediction 3, question 16 : c\n",
      " --> Prediction 3, question 17 : b\n",
      " --> Prediction 3, question 18 : b\n",
      " --> Prediction 3, question 19 : a\n",
      " --> Prediction 3, question 20 : c\n",
      " --> Prediction 3, question 21 : d\n",
      " --> Prediction 3, question 22 : a\n",
      " --> Prediction 3, question 23 : a\n",
      " --> Prediction 3, question 24 : d\n",
      " --> Prediction 4, question 1 : b\n",
      " --> Prediction 4, question 2 : a\n",
      " --> Prediction 4, question 3 : c\n",
      " --> Prediction 4, question 4 : a\n",
      " --> Prediction 4, question 5 : a\n",
      " --> Prediction 4, question 6 : b\n",
      " --> Prediction 4, question 7 : d\n",
      " --> Prediction 4, question 8 : d\n",
      " --> Prediction 4, question 9 : b\n",
      " --> Prediction 4, question 10 : b\n",
      " --> Prediction 4, question 11 : a\n",
      " --> Prediction 4, question 12 : c\n",
      " --> Prediction 4, question 13 : a\n",
      " --> Prediction 4, question 14 : d\n",
      " --> Prediction 4, question 15 : a\n",
      " --> Prediction 4, question 16 : c\n",
      " --> Prediction 4, question 17 : b\n",
      " --> Prediction 4, question 18 : b\n",
      " --> Prediction 4, question 19 : a\n",
      " --> Prediction 4, question 20 : a\n",
      " --> Prediction 4, question 21 : d\n",
      " --> Prediction 4, question 22 : a\n",
      " --> Prediction 4, question 23 : a\n",
      " --> Prediction 4, question 24 : d\n",
      " --> Prediction 5, question 1 : a\n",
      " --> Prediction 5, question 2 : a\n",
      " --> Prediction 5, question 3 : c\n",
      " --> Prediction 5, question 4 : a\n",
      " --> Prediction 5, question 5 : a\n",
      " --> Prediction 5, question 6 : b\n",
      " --> Prediction 5, question 7 : d\n",
      " --> Prediction 5, question 8 : a\n",
      " --> Prediction 5, question 9 : b\n",
      " --> Prediction 5, question 10 : a\n",
      " --> Prediction 5, question 11 : b\n",
      " --> Prediction 5, question 12 : a\n",
      " --> Prediction 5, question 13 : a\n",
      " --> Prediction 5, question 14 : d\n",
      " --> Prediction 5, question 15 : a\n",
      " --> Prediction 5, question 16 : c\n",
      " --> Prediction 5, question 17 : b\n",
      " --> Prediction 5, question 18 : b\n",
      " --> Prediction 5, question 19 : a\n",
      " --> Prediction 5, question 20 : c\n",
      " --> Prediction 5, question 21 : d\n",
      " --> Prediction 5, question 22 : a\n",
      " --> Prediction 5, question 23 : a\n",
      " --> Prediction 5, question 24 : d\n",
      "Mean accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'You are a reliability professor. You will see a multiple choice question. Please output one or several correct answer. You should only return the letter of the correct answer. For example, if you want to say that answer [d] is the right one, you should only retun \"d\". Only one response is admissible'\n",
    "\n",
    "def sendRequestToGPT(prompt,\n",
    "                     context=\"You are a reliability professor. You will see a multiple choice question. Please output one or several correct answer.\",\n",
    "                     print_=False):\n",
    "    try:\n",
    "        # Send a chat completion request to GPT-4\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": context},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Retrieve and print the response text\n",
    "        response_text = response.choices[0].message.content\n",
    "\n",
    "        if print_:\n",
    "            print('Context:')\n",
    "            print(context)\n",
    "            print('')\n",
    "            print('Prompt:')\n",
    "            print(prompt)\n",
    "            print('')\n",
    "            print('GPT-4 Response:')\n",
    "            print(response_text)\n",
    "        return response_text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "class SimpleContext(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "        return sendRequestToGPT(q,context)\n",
    "    \n",
    "v1 = SimpleContext(questions)\n",
    "v1.submission_to_csv('submission.csv')\n",
    "v1.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double Prompting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class FullReasoning(BaseModel):\n",
    "    steps: list[str]\n",
    "    final_answer: Literal[\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a reliability expert. Respond with a, b, c, or d.\n",
    "\"\"\"\n",
    "\n",
    "DOUBT_PROMPT = \"\"\"\n",
    "I have a doubt. Are you totally sure ? Double-check your answer and explain briefly in 2 steps.\n",
    "\"\"\"\n",
    "\n",
    "class DoublePrompting(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": q},\n",
    "        ]\n",
    "\n",
    "        first_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "            max_completion_tokens=50,\n",
    "        )\n",
    "\n",
    "        messages += [\n",
    "            {\"role\": \"assistant\", \"content\": first_response.choices[0].message.content},\n",
    "            {\"role\": \"user\", \"content\": DOUBT_PROMPT},\n",
    "        ]\n",
    "\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "            #max_completion_tokens=300,\n",
    "            response_format=FullReasoning,\n",
    "        )\n",
    "        answer = response.choices[0].message.parsed\n",
    "        return answer.final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.2666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_prompting = DoublePrompting(questions)\n",
    "double_prompting.submission_to_csv('submission.csv')\n",
    "double_prompting.score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
