{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get('OPENAI_API_KEY'),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "from kaggle_submission import SubmissionBase\n",
    "\n",
    "questions = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V1 - Simple Context Improvement**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Prediction 1, question 1 : a\n",
      " --> Prediction 1, question 2 : a\n",
      " --> Prediction 1, question 3 : c\n",
      " --> Prediction 1, question 4 : a\n",
      " --> Prediction 1, question 5 : a\n",
      " --> Prediction 1, question 6 : b\n",
      " --> Prediction 1, question 7 : d\n",
      " --> Prediction 1, question 8 : a\n",
      " --> Prediction 1, question 9 : b\n",
      " --> Prediction 1, question 10 : a\n",
      " --> Prediction 1, question 11 : c\n",
      " --> Prediction 1, question 12 : a\n",
      " --> Prediction 1, question 13 : a\n",
      " --> Prediction 1, question 14 : d\n",
      " --> Prediction 1, question 15 : a\n",
      " --> Prediction 1, question 16 : c\n",
      " --> Prediction 1, question 17 : b\n",
      " --> Prediction 1, question 18 : b\n",
      " --> Prediction 1, question 19 : a\n",
      " --> Prediction 1, question 20 : c\n",
      " --> Prediction 1, question 21 : c\n",
      " --> Prediction 1, question 22 : a\n",
      " --> Prediction 1, question 23 : a\n",
      " --> Prediction 1, question 24 : d\n",
      " --> Prediction 2, question 1 : c\n",
      " --> Prediction 2, question 2 : a\n",
      " --> Prediction 2, question 3 : c\n",
      " --> Prediction 2, question 4 : b\n",
      " --> Prediction 2, question 5 : a\n",
      " --> Prediction 2, question 6 : b\n",
      " --> Prediction 2, question 7 : d\n",
      " --> Prediction 2, question 8 : c\n",
      " --> Prediction 2, question 9 : b\n",
      " --> Prediction 2, question 10 : a\n",
      " --> Prediction 2, question 11 : b\n",
      " --> Prediction 2, question 12 : a\n",
      " --> Prediction 2, question 13 : a\n",
      " --> Prediction 2, question 14 : d\n",
      " --> Prediction 2, question 15 : a\n",
      " --> Prediction 2, question 16 : b\n",
      " --> Prediction 2, question 17 : b\n",
      " --> Prediction 2, question 18 : b\n",
      " --> Prediction 2, question 19 : a\n",
      " --> Prediction 2, question 20 : a\n",
      " --> Prediction 2, question 21 : c\n",
      " --> Prediction 2, question 22 : a\n",
      " --> Prediction 2, question 23 : a\n",
      " --> Prediction 2, question 24 : d\n",
      " --> Prediction 3, question 1 : b\n",
      " --> Prediction 3, question 2 : a\n",
      " --> Prediction 3, question 3 : c\n",
      " --> Prediction 3, question 4 : a\n",
      " --> Prediction 3, question 5 : a\n",
      " --> Prediction 3, question 6 : b\n",
      " --> Prediction 3, question 7 : d\n",
      " --> Prediction 3, question 8 : a\n",
      " --> Prediction 3, question 9 : b\n",
      " --> Prediction 3, question 10 : a\n",
      " --> Prediction 3, question 11 : b\n",
      " --> Prediction 3, question 12 : a\n",
      " --> Prediction 3, question 13 : a\n",
      " --> Prediction 3, question 14 : d\n",
      " --> Prediction 3, question 15 : a\n",
      " --> Prediction 3, question 16 : c\n",
      " --> Prediction 3, question 17 : b\n",
      " --> Prediction 3, question 18 : b\n",
      " --> Prediction 3, question 19 : a\n",
      " --> Prediction 3, question 20 : c\n",
      " --> Prediction 3, question 21 : c\n",
      " --> Prediction 3, question 22 : a\n",
      " --> Prediction 3, question 23 : a\n",
      " --> Prediction 3, question 24 : d\n",
      " --> Prediction 4, question 1 : b\n",
      " --> Prediction 4, question 2 : a\n",
      " --> Prediction 4, question 3 : c\n",
      " --> Prediction 4, question 4 : a\n",
      " --> Prediction 4, question 5 : a\n",
      " --> Prediction 4, question 6 : b\n",
      " --> Prediction 4, question 7 : c\n",
      " --> Prediction 4, question 8 : a\n",
      " --> Prediction 4, question 9 : b\n",
      " --> Prediction 4, question 10 : a\n",
      " --> Prediction 4, question 11 : a\n",
      " --> Prediction 4, question 12 : a\n",
      " --> Prediction 4, question 13 : a\n",
      " --> Prediction 4, question 14 : d\n",
      " --> Prediction 4, question 15 : a\n",
      " --> Prediction 4, question 16 : c\n",
      " --> Prediction 4, question 17 : d\n",
      " --> Prediction 4, question 18 : b\n",
      " --> Prediction 4, question 19 : a\n",
      " --> Prediction 4, question 20 : a\n",
      " --> Prediction 4, question 21 : c\n",
      " --> Prediction 4, question 22 : a\n",
      " --> Prediction 4, question 23 : a\n",
      " --> Prediction 4, question 24 : d\n",
      " --> Prediction 5, question 1 : a\n",
      " --> Prediction 5, question 2 : a\n",
      " --> Prediction 5, question 3 : c\n",
      " --> Prediction 5, question 4 : a\n",
      " --> Prediction 5, question 5 : a\n",
      " --> Prediction 5, question 6 : b\n",
      " --> Prediction 5, question 7 : c\n",
      " --> Prediction 5, question 8 : b\n",
      " --> Prediction 5, question 9 : b\n",
      " --> Prediction 5, question 10 : a\n",
      " --> Prediction 5, question 11 : a\n",
      " --> Prediction 5, question 12 : a\n",
      " --> Prediction 5, question 13 : a\n",
      " --> Prediction 5, question 14 : c\n",
      " --> Prediction 5, question 15 : a\n",
      " --> Prediction 5, question 16 : c\n",
      " --> Prediction 5, question 17 : b\n",
      " --> Prediction 5, question 18 : b\n",
      " --> Prediction 5, question 19 : a\n",
      " --> Prediction 5, question 20 : c\n",
      " --> Prediction 5, question 21 : c\n",
      " --> Prediction 5, question 22 : a\n",
      " --> Prediction 5, question 23 : a\n",
      " --> Prediction 5, question 24 : d\n",
      "Mean accuracy: 0.4833333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4833333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'You are a reliability professor. You will see a multiple choice question. Please output one or several correct answer. You should only return the letter of the correct answer. For example, if you want to say that answer [d] is the right one, you should only retun \"d\". Only one response is admissible'\n",
    "\n",
    "context = \"\"\"\n",
    "You are an AI expert in reliability engineering. Your task is to answer multiple-choice questions (MCQs) accurately and concisely. Each question will have exactly one correct answer.\n",
    "\n",
    "Instructions:\n",
    "- Read the question and the possible answers.\n",
    "- Identify the single correct answer based on your expertise in reliability engineering.\n",
    "- Respond only with the letter of the correct answer (e.g., a, b, c, or d). Do not provide any explanations or additional text.\n",
    "For example, if you want to say that answer [d] is the right one, you should only retun \"d\".\n",
    "\n",
    "\n",
    "Example usage:\n",
    "Question: Which metric measures the average time between system failures?\n",
    "a. MTTR\n",
    "b. MTBF\n",
    "c. Availability\n",
    "d. Failure Rate\n",
    "\n",
    "Expected response:\n",
    "b\n",
    "\"\"\"\n",
    "\n",
    "def sendRequestToGPT(prompt,\n",
    "                     context=\"You are a reliability professor. You will see a multiple choice question. Please output one or several correct answer.\",\n",
    "                     print_=False):\n",
    "    try:\n",
    "        # Send a chat completion request to GPT-4\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": context},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Retrieve and print the response text\n",
    "        response_text = response.choices[0].message.content\n",
    "\n",
    "        if print_:\n",
    "            print('Context:')\n",
    "            print(context)\n",
    "            print('')\n",
    "            print('Prompt:')\n",
    "            print(prompt)\n",
    "            print('')\n",
    "            print('GPT-4 Response:')\n",
    "            print(response_text)\n",
    "        return response_text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "class SimpleContext(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "        return sendRequestToGPT(q,context)\n",
    "    \n",
    "v1 = SimpleContext(questions)\n",
    "v1.submission_to_csv('submission1.csv')\n",
    "v1.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double Prompting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class FullReasoning(BaseModel):\n",
    "    steps: list[str]\n",
    "    final_answer: Literal[\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a reliability expert. Respond with a, b, c, or d.\n",
    "\"\"\"\n",
    "\n",
    "DOUBT_PROMPT = \"\"\"\n",
    "I have a doubt. Are you totally sure ? Double-check your answer and explain briefly in 2 steps.\n",
    "\"\"\"\n",
    "\n",
    "class DoublePrompting(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": q},\n",
    "        ]\n",
    "\n",
    "        first_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "            max_completion_tokens=50,\n",
    "        )\n",
    "\n",
    "        messages += [\n",
    "            {\"role\": \"assistant\", \"content\": first_response.choices[0].message.content},\n",
    "            {\"role\": \"user\", \"content\": DOUBT_PROMPT},\n",
    "        ]\n",
    "\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "            #max_completion_tokens=300,\n",
    "            response_format=FullReasoning,\n",
    "        )\n",
    "        answer = response.choices[0].message.parsed\n",
    "        return answer.final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.2666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_prompting = DoublePrompting(questions)\n",
    "double_prompting.submission_to_csv('submission.csv')\n",
    "double_prompting.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiway prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': 'You are a reliability expert. You will be asked to answer to several questions based on your knowledge and the definitions you know.\\nYou will need to explain your reasonning and explain the steps that allowed you to choose your answers.'}\n",
      "{'user': '[Question]: 2. In general, reliability testing is performed for which of the following reasons?I. To detect unanticipated failure modes.II. To compare estimated failure rates to actual failure rates.III. To monitor reliability growth over time.IV. To meet or exceed customer expectations.'}\n",
      "{'assistant': \"Reliability testing is a critical component in the development and evaluation of products, especially in industries where safety and performance are paramount. Let's analyze the options provided and identify the reasons reliability testing is typically performed.\\n\\nI. **To detect unanticipated failure modes**: This is a valid reason for conducting reliability testing. During testing, unanticipated failure modes can become evident, allowing engineers to address potential weaknesses that had not been foreseen during the design phase. It's an essential aspect of ensuring product reliability.\\n\\nII. **To compare estimated failure rates to actual failure rates**: This comparison is central to reliability testing. By evaluating how actual failure rates align with initial estimates, companies can gain insights into the accuracy of their reliability predictions. If there is a significant discrepancy, this may indicate a need for design changes or improvements in quality control.\\n\\nIII. **To monitor reliability growth over time**: This makes sense as well. Reliability testing can trend the reliability of a product over its lifecycle, identifying how improvements or changes affect overall reliability. This is especially useful for iterative designs or in production environments where continuous improvement is a focus.\\n\\nIV. **To meet or exceed customer expectations**: This is also a significant reason for reliability testing. Customers expect products to perform reliably over their intended lifespan. By ensuring that products meet defined reliability standards, manufacturers can enhance customer satisfaction and trust.\\n\\nIn conclusion, all four statements (I, II, III, IV) provide valid reasons for conducting reliability testing. Each reason addresses different aspects of reliability, from identifying potential failures to enhancing customer satisfaction. Therefore, the answer is that reliability testing is performed for all of the following reasons: I, II, III, and IV.\"}\n",
      "{'user': 'Based on your previous answer, you should now assess the veracity of each of the following possible answers one by one:\\n[Choices]: [a] I and III only | [b] II and IV only | [c] I, II and III only  | [d] I, II, III and IV'}\n",
      "{'assistant': 'Let’s assess the accuracy of each choice regarding the validity of the statements about the reasons for performing reliability testing.\\n\\n### Choice [a]: I and III only\\n- **I (To detect unanticipated failure modes)**: This reason is valid, as reliability testing can reveal previously unforeseen issues.\\n- **III (To monitor reliability growth over time)**: This reason is also valid, as testing over time can demonstrate improvements in reliability.\\n\\nHowever, this choice **does not include** II (comparing estimated to actual failure rates) and IV (meeting/exceeding customer expectations), both of which are valid reasons. Therefore, this choice is **not correct**.\\n\\n### Choice [b]: II and IV only\\n- **II (To compare estimated failure rates to actual failure rates)**: This statement is correct and important for validating reliability predictions.\\n- **IV (To meet or exceed customer expectations)**: This is also a valid reason for performing reliability testing, as customer satisfaction is crucial in product development.\\n\\nThis selection **omits I and III**, which are also valid. So, this choice is **not correct**.\\n\\n### Choice [c]: I, II and III only\\n- **I (To detect unanticipated failure modes)**: Valid.\\n- **II (To compare estimated failure rates to actual failure rates)**: Valid.\\n- **III (To monitor reliability growth over time)**: Valid.\\n\\nHowever, this choice **does not include IV**, which is also a valid reason. Thus, this choice is **not correct**.\\n\\n### Choice [d]: I, II, III and IV\\n- **I (To detect unanticipated failure modes)**: Valid.\\n- **II (To compare estimated failure rates to actual failure rates)**: Valid.\\n- **III (To monitor reliability growth over time)**: Valid.\\n- **IV (To meet or exceed customer expectations)**: Valid.\\n\\nThis choice includes all the reasons discussed, making it the most comprehensive and therefore the **correct choice**.\\n\\nIn summary, the veracity assessment leads us to conclude that the correct answer is **choice [d]: I, II, III and IV**.'}\n",
      "{'user': 'Now please select the 1 possibility that fits bests the initial question.\\nIt is possible that none of the possible answer seems acceptable to you. In this case, please choose the one that is the closest to your opinion.\\nPlease note that only one answer is acceptable and that only the letter of the correct answer is expected. If you want to say that answer [d] is the right one, you should only retun \"d\".'}\n",
      "{'assistant': 'd'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_submission import SequentialQuestions\n",
    "class MultiPrompting(SequentialQuestions):\n",
    "    def get_1_answer(self, q, full_messages=False):\n",
    "        \n",
    "        context = \"\"\"You are a reliability expert. You will be asked to answer to several questions based on your knowledge and the definitions you know.\n",
    "You will need to explain your reasonning and explain the steps that allowed you to choose your answers.\"\"\"\n",
    "\n",
    "        def extract_question(q):\n",
    "            split = q.split('\\n')\n",
    "            return split[0],split[2]\n",
    "        question,choices = extract_question(q)\n",
    "\n",
    "        questions = [\n",
    "            question,\n",
    "            f\"\"\"Based on your previous answer, you should now assess the veracity of each of the following possible answers one by one:\n",
    "{choices}\"\"\",\n",
    "            f\"\"\"Now please select the 1 possibility that fits bests the initial question.\n",
    "It is possible that none of the possible answer seems acceptable to you. In this case, please choose the one that is the closest to your opinion.\n",
    "Please note that only one answer is acceptable and that only the letter of the correct answer is expected. If you want to say that answer [d] is the right one, you should only retun \"d\".\"\"\"\n",
    "        ]\n",
    "\n",
    "        conversation = self._ask_questions_in_a_row(context, questions)\n",
    "\n",
    "        if full_messages:\n",
    "            for i in conversation: print(i)\n",
    "        \n",
    "        return conversation[-1]['assistant']\n",
    "        \n",
    "\n",
    "mp = MultiPrompting(questions)\n",
    "q = \"\"\"[Question]: 2. In general, reliability testing is performed for which of the following reasons?I. To detect unanticipated failure modes.II. To compare estimated failure rates to actual failure rates.III. To monitor reliability growth over time.IV. To meet or exceed customer expectations.\n",
    "\n",
    "[Choices]: [a] I and III only | [b] II and IV only | [c] I, II and III only  | [d] I, II, III and IV\"\"\"\n",
    "mp.get_1_answer(q, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MultiPrompting(questions)\n",
    "mp.submission_to_csv('submission_multi_discussion.csv')\n",
    "mp.score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
