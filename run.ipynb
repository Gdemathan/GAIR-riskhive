{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanrobert/Documents/CS_2024/ORRA/GAIR/GAIR-riskhive/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.kaggle_submission import SubmissionBase, test_submission\n",
    "from src.client import openai_client\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "from src.python_agent import PythonAgent\n",
    "\n",
    "test_questions = pd.read_csv(\"data/test.csv\")\n",
    "train_questions = pd.read_csv(\"data/train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V1 - Simple Context Improvement**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "You are an AI expert in reliability engineering. Your task is to answer multiple-choice questions (MCQs) accurately and concisely. Each question will have exactly one correct answer.\n",
    "\n",
    "Instructions:\n",
    "- Read the question and the possible answers.\n",
    "- Identify the single correct answer based on your expertise in reliability engineering.\n",
    "- Respond only with the letter of the correct answer (e.g., a, b, c, or d). Do not provide any explanations or additional text.\n",
    "For example, if you want to say that answer [d] is the right one, you should only retun \"d\".\n",
    "\n",
    "\n",
    "Example usage:\n",
    "Question: Which metric measures the average time between system failures?\n",
    "a. MTTR\n",
    "b. MTBF\n",
    "c. Availability\n",
    "d. Failure Rate\n",
    "\n",
    "Expected response:\n",
    "b\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SimpleContext(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": context},\n",
    "                {\"role\": \"user\", \"content\": q},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "v1 = SimpleContext(test_questions, openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Prediction 1 for question 1 : d\n",
      " --> Prediction 1 for question 2 : a\n",
      " --> Prediction 1 for question 3 : a\n",
      " --> Prediction 1 for question 4 : d\n",
      " --> Prediction 1 for question 5 : a\n",
      " --> Prediction 1 for question 6 : d\n",
      " --> Prediction 1 for question 7 : b\n",
      " --> Prediction 1 for question 8 : b\n",
      " --> Prediction 1 for question 9 : c\n",
      " --> Prediction 1 for question 10 : d\n",
      " --> Prediction 1 for question 11 : d\n",
      " --> Prediction 1 for question 12 : d\n",
      " --> Prediction 1 for question 13 : b\n",
      " --> Prediction 1 for question 14 : b\n",
      " --> Prediction 1 for question 15 : c\n",
      " --> Prediction 1 for question 16 : b\n",
      " --> Prediction 1 for question 17 : d\n",
      " --> Prediction 1 for question 18 : d\n",
      " --> Prediction 1 for question 19 : a\n",
      " --> Prediction 1 for question 20 : c\n",
      " --> Prediction 1 for question 21 : c\n",
      " --> Prediction 1 for question 22 : c\n",
      " --> Prediction 1 for question 23 : b\n",
      " --> Prediction 1 for question 24 : b\n",
      " --> Prediction 1 for question 25 : a\n",
      "--------------------\n",
      "Score : 0.56 for model SimpleContext\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.56)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission(v1, fake_multiple_attempts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double Prompting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullReasoning(BaseModel):\n",
    "    steps: list[str]\n",
    "    final_answer: Literal[\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = context\n",
    "\n",
    "DOUBT_PROMPT = \"\"\"\n",
    "I have a doubt. Are you totally sure ? Double-check your answer and explain briefly in 2 steps.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DoublePrompting(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": q},\n",
    "        ]\n",
    "\n",
    "        first_response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "        )\n",
    "\n",
    "        messages += [\n",
    "            {\"role\": \"assistant\", \"content\": first_response.choices[0].message.content},\n",
    "            {\"role\": \"user\", \"content\": DOUBT_PROMPT},\n",
    "        ]\n",
    "\n",
    "        response = openai_client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "            response_format=FullReasoning,\n",
    "        )\n",
    "        answer = response.choices[0].message.parsed\n",
    "        return answer.final_answer\n",
    "    \n",
    "double_prompting = DoublePrompting(test_questions, openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Prediction 1 for question 1 : d\n",
      " --> Prediction 1 for question 2 : b\n",
      " --> Prediction 1 for question 3 : a\n",
      " --> Prediction 1 for question 4 : d\n",
      " --> Prediction 1 for question 5 : a\n",
      " --> Prediction 1 for question 6 : d\n",
      " --> Prediction 1 for question 7 : b\n",
      " --> Prediction 1 for question 8 : b\n",
      " --> Prediction 1 for question 9 : c\n",
      " --> Prediction 1 for question 10 : d\n",
      " --> Prediction 1 for question 11 : d\n",
      " --> Prediction 1 for question 12 : d\n",
      " --> Prediction 1 for question 13 : b\n",
      " --> Prediction 1 for question 14 : b\n",
      " --> Prediction 1 for question 15 : c\n",
      " --> Prediction 1 for question 16 : b\n",
      " --> Prediction 1 for question 17 : d\n",
      " --> Prediction 1 for question 18 : d\n",
      " --> Prediction 1 for question 19 : c\n",
      " --> Prediction 1 for question 20 : c\n",
      " --> Prediction 1 for question 21 : c\n",
      " --> Prediction 1 for question 22 : b\n",
      " --> Prediction 1 for question 23 : c\n",
      " --> Prediction 1 for question 24 : b\n",
      " --> Prediction 1 for question 25 : a\n",
      "--------------------\n",
      "Score : 0.56 for model DoublePrompting\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission(double_prompting, fake_multiple_attempts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiway prompting**\n",
    "\n",
    "This time we initially don't provide the choices to Chat. We first let it think about an answer, and then provide it the MCQ in order to choose the best answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a reliability expert. You will be asked to answer to several questions based on your knowledge and the definitions you know.\n",
    "You will need to explain your reasonning and explain the steps that allowed you to choose your answers.\n",
    "\"\"\"\n",
    "\n",
    "class SimpleAnswer(BaseModel):\n",
    "    choice: Literal[\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "\n",
    "def provide_choices(choices):\n",
    "    return f\"\"\"Based on your previous answer, you should now assess the veracity of each of the following possible answers one by one:\n",
    "{choices}\"\"\"\n",
    "\n",
    "SELECTION_PROMPT = \"\"\"Now please select the 1 possibility that fits bests the initial question.\n",
    "It is possible that none of the possible answer seems acceptable to you. In this case, please choose the one that is the closest to your opinion.\"\"\"\n",
    "\n",
    "\n",
    "class MultiPrompting(SubmissionBase):\n",
    "    def get_1_answer(self, q):\n",
    "        question, choices = q.split(\"[Choices]\")\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "\n",
    "        first_response = (\n",
    "            openai_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                temperature=0.61,\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "\n",
    "        messages += [\n",
    "            {\"role\": \"assistant\", \"content\": first_response},\n",
    "            {\"role\": \"user\", \"content\": provide_choices(choices)},\n",
    "        ]\n",
    "\n",
    "        chat_opinion = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "        ).choices[0].message.content\n",
    "\n",
    "        messages += [\n",
    "            {\"role\": \"assistant\", \"content\": chat_opinion},\n",
    "            {\"role\": \"user\", \"content\": SELECTION_PROMPT},\n",
    "        ]\n",
    "\n",
    "        return openai_client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.61,\n",
    "            response_format=SimpleAnswer,\n",
    "        ).choices[0].message.parsed.choice\n",
    "    \n",
    "mp = MultiPrompting(test_questions, openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Prediction 1 for question 1 : d\n",
      " --> Prediction 1 for question 2 : d\n",
      " --> Prediction 1 for question 3 : a\n",
      " --> Prediction 1 for question 4 : d\n",
      " --> Prediction 1 for question 5 : a\n",
      " --> Prediction 1 for question 6 : d\n",
      " --> Prediction 1 for question 7 : b\n",
      " --> Prediction 1 for question 8 : c\n",
      " --> Prediction 1 for question 9 : c\n",
      " --> Prediction 1 for question 10 : d\n",
      " --> Prediction 1 for question 11 : d\n",
      " --> Prediction 1 for question 12 : a\n",
      " --> Prediction 1 for question 13 : a\n",
      " --> Prediction 1 for question 14 : b\n",
      " --> Prediction 1 for question 15 : b\n",
      " --> Prediction 1 for question 16 : a\n",
      " --> Prediction 1 for question 17 : d\n",
      " --> Prediction 1 for question 18 : d\n",
      " --> Prediction 1 for question 19 : c\n",
      " --> Prediction 1 for question 20 : b\n",
      " --> Prediction 1 for question 21 : a\n",
      " --> Prediction 1 for question 22 : a\n",
      " --> Prediction 1 for question 23 : a\n",
      " --> Prediction 1 for question 24 : c\n",
      " --> Prediction 1 for question 25 : a\n",
      "--------------------\n",
      "Score : 0.72 for model MultiPrompting\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.72)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission(mp, fake_multiple_attempts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agentic system**\n",
    "\n",
    "Now we will give the model the capacity to write and execute Python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import scipy.stats as stats\n",
      "\n",
      "# Given values\n",
      "mean = 150  # Mean (μ)\n",
      "std_dev = 20  # Standard deviation (σ)\n",
      "percentile = 0.10  # 10th percentile\n",
      "\n",
      "# Find the z-score for the 10th percentile\n",
      "z_score = stats.norm.ppf(percentile)\n",
      "\n",
      "# Calculate B10 life\n",
      "B10_life = mean + z_score * std_dev\n",
      "print(B10_life)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 124.36896868910799\n",
      " --> Prediction 1 for question 1 : b\n",
      " --> Prediction 1 for question 2 : a\n",
      " --> Prediction 1 for question 3 : c\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import scipy.stats as stats\n",
      "\n",
      "# Parameters\n",
      "n = 20  # sample size\n",
      "alpha = 0.05\n",
      "\n",
      "# Degrees of freedom\n",
      "df = n - 1\n",
      "\n",
      "# Chi-squared critical values\n",
      "chi2_lower = stats.chi2.ppf(alpha / 2, df)\n",
      "chi2_upper = stats.chi2.ppf(1 - alpha / 2, df)\n",
      "\n",
      "(chi2_lower, chi2_upper)\n",
      "```\n",
      "The script returned no output. Trying again\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import scipy.stats as stats\n",
      "\n",
      "# Parameters\n",
      "n = 20  # sample size\n",
      "alpha = 0.05\n",
      "\n",
      "# Degrees of freedom\n",
      "df = n - 1\n",
      "\n",
      "# Chi-squared critical values\n",
      "chi2_lower = stats.chi2.ppf(alpha / 2, df)\n",
      "chi2_upper = stats.chi2.ppf(1 - alpha / 2, df)\n",
      "\n",
      "# Sample variance\n",
      "s2 = 4\n",
      "\n",
      "# Confidence interval for population variance\n",
      "lower_bound = (df * s2) / chi2_upper\n",
      "upper_bound = (df * s2) / chi2_lower\n",
      "\n",
      "print(lower_bound, upper_bound)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 2.3133825594720308 8.533078016943891\n",
      " --> Prediction 1 for question 4 : a\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "\n",
      "# Given values\n",
      "mean = 10  # sample mean\n",
      "std_dev = 2  # sample standard deviation\n",
      "n = 50  # sample size\n",
      "Z = 1.96  # Z-score for 95% confidence\n",
      "\n",
      "# Calculate standard error\n",
      "SE = std_dev / math.sqrt(n)\n",
      "\n",
      "# Calculate margin of error\n",
      "ME = Z * SE\n",
      "\n",
      "# Calculate confidence interval\n",
      "lower_bound = mean - ME\n",
      "upper_bound = mean + ME\n",
      "lower_bound, upper_bound\n",
      "```\n",
      "The script returned no output. Trying again\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "\n",
      "# Given values\n",
      "mean = 10  # sample mean\n",
      "std_dev = 2  # sample standard deviation\n",
      "n = 50  # sample size\n",
      "Z = 1.96  # Z-score for 95% confidence\n",
      "\n",
      "# Calculate standard error\n",
      "SE = std_dev / math.sqrt(n)\n",
      "\n",
      "# Calculate margin of error\n",
      "ME = Z * SE\n",
      "\n",
      "# Calculate confidence interval\n",
      "lower_bound = mean - ME\n",
      "upper_bound = mean + ME\n",
      "\n",
      "print(lower_bound, upper_bound)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 9.445628283549746 10.554371716450254\n",
      " --> Prediction 1 for question 5 : d\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "# Given data\n",
      "failure_times = np.array([700, 900, 1000, 1100, 1300])\n",
      "shape_parameter = 2\n",
      "n_failures = len(failure_times)\n",
      "\n",
      "# MLE for eta\n",
      "eta_hat = (1/n_failures) * np.sum(failure_times**shape_parameter) * (n_failures / np.sum(failure_times**(shape_parameter - 1)))**(1/shape_parameter)\n",
      "print(eta_hat)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 32887.687665751146\n",
      " --> Prediction 1 for question 6 : a\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "from math import comb\n",
      "\n",
      "R = 0.995  # Reliability\n",
      "F = 1 - R  # Failure probability\n",
      "\n",
      "# Probability of exactly 2 engines functioning\n",
      "P_2 = comb(3, 2) * (R ** 2) * (F ** 1)\n",
      "\n",
      "# Probability of all 3 engines functioning\n",
      "P_3 = comb(3, 3) * (R ** 3)\n",
      "\n",
      "# Total probability of success\n",
      "P_success = P_2 + P_3\n",
      "print(P_success)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.99992525\n",
      " --> Prediction 1 for question 7 : d\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "\n",
      "beta = 0.5\n",
      "eta = 10000\n",
      "t = 8760  # 1 year in hours\n",
      "\n",
      "# Calculate the probability that the component is still operational after 1 year\n",
      "probability_operational = math.exp(-((t / eta) ** beta))\n",
      "print(probability_operational)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.39221358944618695\n",
      " --> Prediction 1 for question 8 : a\n",
      " --> Prediction 1 for question 9 : a\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "# Given probabilities\n",
      "P_C = 0.05  # Probability of having a crack\n",
      "P_S_given_C = 0.98  # Probability of signaling a crack given there is a crack\n",
      "P_S_given_not_C = 0.03  # Probability of signaling a crack given there is no crack\n",
      "\n",
      "# Probability of not having a crack\n",
      "P_not_C = 1 - P_C\n",
      "\n",
      "# Total probability of signaling a crack\n",
      "P_S = (P_S_given_C * P_C) + (P_S_given_not_C * P_not_C)\n",
      "\n",
      "# Bayes' theorem to find the probability that a part has a crack given the signal\n",
      "P_C_given_S = (P_S_given_C * P_C) / P_S\n",
      "\n",
      "print(P_C_given_S)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.6322580645161291\n",
      " --> Prediction 1 for question 10 : c\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "\n",
      "lambda_ = 7\n",
      "\n",
      "# Poisson probability mass function\n",
      "def poisson_pmf(k, lambda_):\n",
      "    return (math.exp(-lambda_) * (lambda_ ** k)) / math.factorial(k)\n",
      "\n",
      "# Calculate P(X < 3)\n",
      "probability_less_than_3 = sum(poisson_pmf(k, lambda_) for k in range(3))\n",
      "\n",
      "print(probability_less_than_3)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.029636163880521777\n",
      " --> Prediction 1 for question 11 : c\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import numpy as np\n",
      "from scipy.stats import weibull_min\n",
      "\n",
      "data = np.array([-309, 229, 386, -104, 180, -217, -167, 168, 122, 138])\n",
      "uncensored_data = data[data > 0]\n",
      "params = weibull_min.fit(uncensored_data, floc=0)\n",
      "beta, loc, scale = params\n",
      "eta = scale\n",
      "t0 = loc\n",
      "beta, eta, t0\n",
      "```\n",
      "The script returned no output. Trying again\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import numpy as np\n",
      "from scipy.stats import weibull_min\n",
      "\n",
      "data = np.array([-309, 229, 386, -104, 180, -217, -167, 168, 122, 138])\n",
      "uncensored_data = data[data > 0]\n",
      "params = weibull_min.fit(uncensored_data, floc=0)\n",
      "beta, loc, scale = params\n",
      "eta = scale\n",
      "t0 = loc\n",
      "print(beta, eta, t0)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 2.446499106633478 230.7777675029722 0\n",
      " --> Prediction 1 for question 12 : c\n",
      " --> Prediction 1 for question 13 : a\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "from scipy.stats import binom\n",
      "\n",
      "# Parameters\n",
      "n = 25  # number of trials\n",
      "p = 0.10  # probability of a part being defective\n",
      "k = 6  # we want cumulative probability up to 6 defective parts\n",
      "\n",
      "# Cumulative probability of 6 or fewer defective parts\n",
      "P_X_leq_6 = binom.cdf(k, n, p)\n",
      "\n",
      "# Probability of 7 or more defective parts\n",
      "P_X_geq_7 = 1 - P_X_leq_6\n",
      "\n",
      "P_X_geq_7\n",
      "```\n",
      "The script returned no output. Trying again\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "from scipy.stats import binom\n",
      "\n",
      "# Parameters\n",
      "n = 25  # number of trials\n",
      "p = 0.10  # probability of a part being defective\n",
      "k = 6  # we want cumulative probability up to 6 defective parts\n",
      "\n",
      "# Cumulative probability of 6 or fewer defective parts\n",
      "P_X_leq_6 = binom.cdf(k, n, p)\n",
      "\n",
      "# Probability of 7 or more defective parts\n",
      "P_X_geq_7 = 1 - P_X_leq_6\n",
      "\n",
      "print(P_X_geq_7)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.009476360691506591\n",
      " --> Prediction 1 for question 14 : c\n",
      " --> Prediction 1 for question 15 : b\n",
      " --> Prediction 1 for question 16 : a\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import numpy as np\n",
      "from scipy.stats import chi2\n",
      "\n",
      "# Failure times\n",
      "failure_times = [632, 3450, 816, 928, 150]\n",
      "n = len(failure_times)\n",
      "\n",
      "# Calculate MTTF\n",
      "mttf = np.mean(failure_times)\n",
      "\n",
      "# Calculate chi-square values\n",
      "alpha = 0.1\n",
      "chi2_lower = chi2.ppf(alpha/2, 2*n)\n",
      "chi2_upper = chi2.ppf(1-alpha/2, 2*n)\n",
      "\n",
      "# Calculate confidence bounds\n",
      "lower_bound = (n / chi2_upper) * mttf\n",
      "upper_bound = (n / chi2_lower) * mttf\n",
      "\n",
      "lower_bound, upper_bound\n",
      "```\n",
      "The script returned no output. Trying again\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import numpy as np\n",
      "from scipy.stats import chi2\n",
      "\n",
      "# Failure times\n",
      "failure_times = [632, 3450, 816, 928, 150]\n",
      "n = len(failure_times)\n",
      "\n",
      "# Calculate MTTF\n",
      "mttf = np.mean(failure_times)\n",
      "\n",
      "# Calculate chi-square values\n",
      "alpha = 0.1\n",
      "chi2_lower = chi2.ppf(alpha/2, 2*n)\n",
      "chi2_upper = chi2.ppf(1-alpha/2, 2*n)\n",
      "\n",
      "# Calculate confidence bounds\n",
      "lower_bound = (n / chi2_upper) * mttf\n",
      "upper_bound = (n / chi2_lower) * mttf\n",
      "\n",
      "print(lower_bound, upper_bound)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 326.43183362646084 1516.6361216640962\n",
      " --> Prediction 1 for question 17 : c\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "MTTF = -100 / math.log(0.99)\n",
      "print(MTTF)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 9949.916247342207\n",
      " --> Prediction 1 for question 18 : b\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "\n",
      "# Given values\n",
      "R_t = 0.95  # reliability for one month\n",
      "t = 1       # time in months\n",
      "\n",
      "# Calculate the failure rate (lambda)\n",
      "lambda_ = -math.log(R_t) / t\n",
      "\n",
      "# Calculate the mean number of failures in one year\n",
      "mu = lambda_ * 12\n",
      "\n",
      "# Calculate P(X <= 2)\n",
      "P_X_le_2 = (math.exp(-mu) * (mu**0) / math.factorial(0) +\n",
      "             math.exp(-mu) * (mu**1) / math.factorial(1) +\n",
      "             math.exp(-mu) * (mu**2) / math.factorial(2))\n",
      "\n",
      "# Calculate P(X > 2)\n",
      "P_X_gt_2 = 1 - P_X_le_2\n",
      "\n",
      "# Print the result\n",
      "print(P_X_gt_2)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.02467615186688754\n",
      " --> Prediction 1 for question 19 : b\n",
      "Found a python script to execute.\n",
      "Executing the following script: \n",
      "\n",
      "import math\n",
      "\n",
      "# Given values\n",
      "lambda_total = 1  # total failure rate\n",
      "t = 6  # time in months\n",
      "k = 2  # number of parts\n",
      "\n",
      "# Calculating P(X <= t)\n",
      "prob_X_le_t = 1 - math.exp(-lambda_total * t) * (1 + lambda_total * t)\n",
      "\n",
      "# Therefore, P(X > t)\n",
      "prob_X_gt_t = 1 - prob_X_le_t\n",
      "print(prob_X_gt_t)\n",
      "```\n",
      "Script executed successfully.\n",
      "Prompting with the result: 0.017351265236664526\n",
      " --> Prediction 1 for question 20 : c\n",
      " --> Prediction 1 for question 21 : c\n",
      " --> Prediction 1 for question 22 : a\n",
      " --> Prediction 1 for question 23 : a\n",
      " --> Prediction 1 for question 24 : d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>prediction_2</th>\n",
       "      <th>prediction_3</th>\n",
       "      <th>prediction_4</th>\n",
       "      <th>prediction_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_id prediction_1 prediction_2 prediction_3 prediction_4  \\\n",
       "0             1            b            b            b            b   \n",
       "1             2            a            a            a            a   \n",
       "2             3            c            c            c            c   \n",
       "3             4            a            a            a            a   \n",
       "4             5            d            d            d            d   \n",
       "5             6            a            a            a            a   \n",
       "6             7            d            d            d            d   \n",
       "7             8            a            a            a            a   \n",
       "8             9            a            a            a            a   \n",
       "9            10            c            c            c            c   \n",
       "10           11            c            c            c            c   \n",
       "11           12            c            c            c            c   \n",
       "12           13            a            a            a            a   \n",
       "13           14            c            c            c            c   \n",
       "14           15            b            b            b            b   \n",
       "15           16            a            a            a            a   \n",
       "16           17            c            c            c            c   \n",
       "17           18            b            b            b            b   \n",
       "18           19            b            b            b            b   \n",
       "19           20            c            c            c            c   \n",
       "20           21            c            c            c            c   \n",
       "21           22            a            a            a            a   \n",
       "22           23            a            a            a            a   \n",
       "23           24            d            d            d            d   \n",
       "\n",
       "   prediction_5  \n",
       "0             b  \n",
       "1             a  \n",
       "2             c  \n",
       "3             a  \n",
       "4             d  \n",
       "5             a  \n",
       "6             d  \n",
       "7             a  \n",
       "8             a  \n",
       "9             c  \n",
       "10            c  \n",
       "11            c  \n",
       "12            a  \n",
       "13            c  \n",
       "14            b  \n",
       "15            a  \n",
       "16            c  \n",
       "17            b  \n",
       "18            b  \n",
       "19            c  \n",
       "20            c  \n",
       "21            a  \n",
       "22            a  \n",
       "23            d  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PythonAgent.inject_python(openai_client=openai_client)\n",
    "test_submission(double_prompting, fake_multiple_attempts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG prompting**\n",
    "\n",
    "We now augment the knowledge of our model using Retrieval Augmented Generation. We built a database containing specific information about reliability engineering, and will use it to augment our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
